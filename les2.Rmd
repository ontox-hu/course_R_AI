# Lesson 2 - Data types and structures in R

```{r include=FALSE}
load("course_urls.RData")
les <- 2
```

![](images/02_1_rlogo.png)

## Contents day 2

 - Reading and cleaning data
 - Visualizations

## Learning objectives

After this lesson:

- You can import data into the R environment
- You know how to inspect your data
- You can make your data "tidy"
- You can visualize categorical data with ggplot.
- You can visualize continuous data with ggplot.
- You can summarize data using boxplots.
- you can perform the most common statistical tests with R.

## Importing text files

So far, we have worked with built-in datasets. In real life you will generate data yourself or you will obtain data from other researchers or public sources such as [NCBI](https://www.ncbi.nlm.nih.gov/).

To start working with your own datasets, data needs to be read by R and stored as R objects. We can use a variety of  `read_function()` from the the [tidyverse](https://www.tidyverse.org/) packages to import plain text datafiles as tibbles (sort of like a data table). These functions work the same. If you have mastered one  you can use the other functions in a similar way:

```{r eval=F}
read_csv()       ## comma separated values
read_csv2()      ## semicolon separated values
read_tsv()       ## tab separated values
read_delim()     ## custom defined delimiter, for example: 
read_delim("voorbeeld.csv", delim="&")
read_fwf()       ## fixed width fields
read_table()     ## white space separated 
```

### separators 

Before choosing the right `read_function()` you need to know how the values of your dataset are separated. 

You can view files by clicking on them in the files tab (lower right corner of the screen). 
```{r echo=FALSE, message=FALSE, out.width = "80%"}
knitr::include_graphics("images/01_3_Rstudio.jpg")
```

**download the datasets for this lesson here: [click](data/lesson3.zip)**

**unzip the folder and place it within your project folder**

**click on heights.csv, select view**

Values of the heights.csv file are separated by comma's. Even though the filename ends on csv (comma separated values) always inspect the contents of a datafile before loading it into R! 

We can use the read_csv() function:

###### Example
```{r}
library(tidyverse)
heights <- read_csv("data/lesson3/heights.csv")
```

you can view the data by typing the object name in the console (or in a script and run that line):

```{r, eval=F}
heights
```

R assumes the decimal separator is a "point". If your datafile has a comma as a decimal separator (most european datafiles) you have to tell the `read_function()` this!

We will use a datafile which is present in the server folder **data/lesson3** named **heights3.txt**. Inspect the datafile heights3.txt. As you can see, 
the values are tab separated and the decimal separator is a comma.

We will first use the `read_tsv()` function with default settings:

###### Example
```{r}
heights_3 <- read_tsv("data/lesson3/heights3.txt")
heights_3
```

The values of variable height are not shown correctly:

* row1 original value = 74,4244387818035. 
* row1 converted value = 7.44e14

We have to instruct `read_tsv()` that the comma acts a decimal separator by using the locale argument in combination with the `locale()` function:

###### Example
```{r}
heights_3 <- read_tsv("data/lesson3/heights3.txt", 
                      locale = locale(decimal_mark = ","))
heights_3
```

Now the values of the height variable are read in correctly.

<div class="question">
##### Exercise `r les` {-} 

Import data datafile heights4.txt in server folder data/lesson3 into R.
</div>

<details><summary>Click for the answer</summary>
```{r}
heights4 <- read_delim("data/lesson3/heights4.txt", delim="@", locale = locale(decimal_mark = ","))
heights4
```
</details>



## Setting variable (column) names

By default `read_function()` uses the first line of a dataset as variable names (column names). 

There are two situations where we have to change the behaviour of the `read_function()`

<div class="tip">
If a dataset doesn't contain variable names (=column names) use the option col_names = FALSE.
</div>

The first line of the dataset will be ignored as variable names. The columns will be labelled automatically from X1 to Xn. If you want to manually add variable names you can provide a vector with the variable names tot the col_names option: col_names = c("variable_name1", "variable_name2", "variable_name3")

Download dataset [heights1.csv](downloaddata/heights1.csv) and move the file to the server folder data/lesson3. To move files between the server and your computer:

**Go to the server, select the folder you want to upload something to.**

**click on Upload**

```{r , echo=FALSE, message=FALSE, out.width = "60%"}
knitr::include_graphics("images/03_3_uploadles.PNG")
```

**In the upload menu, click Choose File and select heights.csv where you just downloaded it.**

**inspect heights.csv**

This file lacks variable names:

###### Example
```{r include=FALSE}
heights_1 <- read_csv("downloaddata/heights1.csv", col_names = FALSE) 
```
```{r eval=FALSE}
heights_1 <- read_csv("data/lesson3/heights1.csv", col_names = FALSE)  # first line will not be used as variable names 
```
```{r}
head(heights_1)
```

```{r include=FALSE}
heights_1_1 <- read_csv("downloaddata/heights1.csv",  col_names = c("name1", "name2", "name3", "name4", "name5", "name6"))  
```
```{r eval=FALSE}
heights_1_1 <- read_csv("data/lesson3/heights1.csv",  col_names = c("name1", "name2", "name3", "name4", "name5", "name6"))  
# added custom variable names by providing a vector containing the names of the variables
# in this case: "name1, name2  name3 etc"
```
```{r}
head(heights_1_1)
```

Variables names can always be modified by using:

* The function `colnames()`
* The function `rename()`


###### Example
```{r eval=FALSE}
heights_1 <- read_csv("data/lesson3/heights1.csv", col_names = FALSE) 
```
```{r}
colnames(heights_1)<- c("name1", "name2", "name3", "name4", "name5", "name6")   # change all column names 
colnames(heights_1)[3] <- "new_name3"   # change the name of a specified column using an index
heights_1_1 <-rename(heights_1_1,  new_name4 = name4) # change the name of a specified column using rename() 
```

<div class="tip">
**(2) if variable names are present but not at the first line use te options skip=N or comment = "#"**
</div>

Download dataset [heights2.txt](downloaddata/heights2.txt) and move the file to the server folder data/lesson3. This file contains variable names but not at the first row. Note that the values are separated by tabs!

**First we have to inspect the datafile: click on the file.**

The first two lines are comments starting with the # sign. The variable names are present at row3.  To read in the file we will use read_tsv()

###### Example
```{r include = FALSE}
heights_2<-read_tsv("downloaddata/heights2.txt", skip = 2) 
```

```{r eval=FALSE}
heights_2<-read_tsv("data/lesson3/heights2.txt", skip = 2) # first two rows are not imported in object heights_2
```
```{r}
heights_2
```

Alternatively we can use the comment = "#" option

###### Example
```{r include = FALSE}
heights_2<-read_tsv("downloaddata/heights2.txt", comment = "#")
```
```{r eval=FALSE}
heights_2<-read_tsv("data/lesson3/heights2.txt", comment = "#")      ## lines starting with a # sign are ignored for read in
```
```{r}
heights_2
```

<div class="question">
##### Exercise `r les` {-}  
Import datafile iris in server folder data/lesson3 into R.

This file lacks column names and starts with comments. Import the datafile without the comment lines and add columns names "Sepal.Length", "Sepal.Width",  "Petal.Length", "Petal.Width", "Species" to the imported dataset.
</div>

<details><summary>Click for the answer</summary>
```{r}
iris_flower<-read_tsv("data/lesson3/iris",
           comment = "#",
           col_names = c("Sepal.Length", "Sepal.Width", "Petal.Length", "Petal.Width", "Species"))
```
</details>


## Importing Excel files

To import Excel files directly into R we can use `read_excel()` function of the readxl package which is part of tidyverse. When Using `read_excel()` Excel datasheets will be converted to a tibble. `read_excel()` reads both xls and xlsx files and detects the format from the extension.

More information about the readxl package can be found at [tidyverse.org](https://readxl.tidyverse.org/)

NOTE: Sometimes it's more convenient to organise your data in Excel and copy the values as plain text in a text editor such as notepad. Subsequently, import the file using the appropiate read_function() described on the previous page.


###### Example
```{r}
library(tidyverse)
library(readxl)                               # you have to explicity load the readxl library
excel_sheets("data/lesson3/datasets.xlsx")    # inspect how many datasheets are present in the excel file
                              
datasets_iris<-read_excel("data/lesson3/datasets.xlsx")    # default behaviour is to import the first datasheet. 
```

Excel files can have multiple datasheets. To specifically select a datasheet use the sheet = "sheetname" or sheet = number option

###### Example
```{r}
datasets_mtcars<-read_excel("data/lesson3/datasets.xlsx", sheet = "mtcars")  # select Excel datasheet named "mtcars"
datasets_quakes<-read_excel("data/lesson3/datasets.xlsx",  sheet = 4)        # select the 4th Excel datasheet (= "quakes")
```

Datafiles in Excel might not always contain column names (=variable names). If the first row doesn't contain column names we have to tell read_excel() to treat the first row as values and not as variable names by using the col_names=FALSE option. 

###### Example
```{r}
datasets_iris_2<-read_excel("data/lesson3/datasets.xlsx", sheet = 5, col_names = FALSE) 
```

If you want to rename the column names you can use the rename() or the colnames() functions (see [Setting variable (column) names])

<div class="question">
##### Exercise `r les` {-} 
Import sheet "quakes_1" from datafile datasets.xlsx  in server folder data/lesson3 into R. Column names are not listed in datasets.xlsx. Import the datafile and add columns names "lat" "long" "depth" "mag" "stations" to the imported data.
</div>

<details><summary>Click for the answer</summary>
```{r}
library(readxl)
read_excel("data/lesson3/datasets.xlsx",
    sheet = "quakes_1",
    col_names = c("lat", "long", "depth", "mag", "stations"))
```
</details>

## Saving and importing R_Objects

* To import data in plain text  format we use the function read_function() 
* To import data in Excel format we use the function read_excel()

It is also possible to save an R object directly to the server and to read the file from the server in the R environment:

To save an R object to the server use the function `saveRDS()`

To import data that is stored as an R object we make use of the function `readRDS()`

###### Example
```{r eval=FALSE}
library(dslabs)                              # we will use a dataset called olive from the dslabs package                       
View(olive)
saveRDS(olive, "data/lesson3/olive.rds")     # object olive is saved as file olive.rds in server folder data/lesson3   
```

To import this R object from the server into RStudio use `readRDS()`. This function takes 1 argument. Assign the R object from the server to a new object name in Rstudio!

###### Example
```{r eval=FALSE}
olive_from_server <- readRDS("data/lesson3/olive.rds")                    ## the path to the file must be quoted
```

## Inspecting your data

Data wrangling: the process of transforming and mapping data from a "raw" data format into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics and visualization ([wikipedia] (https://en.wikipedia.org/wiki/Data_wrangling))

The first step in data wrangling is to inspect the structure of the dataset.  We've already seen some functions to inspect the data. Important questions are:

* What is the datastructure?
* How many variables does the dataset contain?
* What are the names of the variables?
* What are the data types of the variables?
* What are possible categories (factors)?
* What are the levels of the categories?
* Are there NA values?
* Is the data **tidy**?

Let's recall some previously used functions to inspect the data. We will use data from the "dslabs" package.

###### Example
```{r message=FALSE}

library(tidyverse)
library(dslabs)
```
```{r eval=FALSE}
?divorce_margarine      # information about the divorce_margarine dataset from the "dslabs" package
```
```{r message=FALSE}
divorce_margarine_tbl <- as_tibble(divorce_margarine)      # converting dataframe to tibble                    
divorce_margarine_tbl 
```


Let's inspect another dataset from the dslabs package: gapminder

###### Example
```{r eval=FALSE}
?gapminder                                       # information about the "gapminder" dataset
```

```{r}
gapminder_tbl <- as_tibble(gapminder)            # converting dataframe to tibble
gapminder_tbl
levels(gapminder_tbl$continent)                # categories in the continent variable
sum(is.na(gapminder_tbl$infant_mortality))   # count the missing (NA) values
```

The last question of the inspection list is:

Is the data **tidy**?

Before we can answer this question we have to know what tidy data is.

***

## What is tidy data?

Tidy data is a way of organising your data in a neat and structured way. If you make your data tidy, it is ensured that it is compatible with data analysis tools from the [tidyverse](https://www.tidyverse.org/) package. A detailed explanation can be found in [chapter12](https://r4ds.had.co.nz/tidy-data.html) in the e-book R for Data Science

However, it is important to note that data does not always need to be tidy. Other R packages require different data organisation formats!

So what is tidy data:

1. Each variable must have its own column.  
1. Each observation must have its own row. 
1. Each value must have its own cell.

*Table1: Example of tidy data*

| country 	| year 	| population 	| birth rate 	|
|:---------	|:-----	|:----------	|:-----------	|
| mali    	| 2001 	| 10.000.000 	| 6.88       	|
| mali    	| 2010 	| 15.000.000 	| 6.06       	|
| sweden  	| 2001 	| 9.000.000  	| 1.57       	|
| sweden  	| 2010 	| 10.000.000 	| 1.85       	|


Each variable must have its own column.  

```{r , echo=FALSE, message=FALSE, out.width = "60%"}
knitr::include_graphics("images/03_4_tidy1.jpg")
```

Each observation must have its own row. 

```{r , echo=FALSE, message=FALSE, out.width = "60%"}
knitr::include_graphics("images/03_5_tidy2.jpg")
```

Each value must have its own cell.

```{r , echo=FALSE, message=FALSE, out.width = "60%"}
knitr::include_graphics("images/03_6_tidy3.jpg")
```

So the following table would by untidy, as there are multiple observations per row:

*Table2: Example of untidy data*

| student  	| EDCC 	| molbio 	| immunologie 	| BID 	|
|:----------	|:------	|:--------	|:-------------	|:-----	|
| Pietje   	| 7.5  	| 6      	| 8.2         	| 8   	|
| Marietje 	| 8    	| 7.9    	| 5           	| 9   	|


This would be the tidy version:

*Table3: Example of untidy data made tidy*

| student  	| course      	| grade 	|
|:----------	|:-------------	|:-------	|
| Pietje   	| EDCC        	| 7.5   	|
| Pietje   	| molbio      	| 6     	|
| Pietje   	| immunologie 	| 8.2   	|
| Pietje   	| BID         	| 8     	|
| Marietje 	| EDCC        	| 8     	|
| Marietje 	| molbio      	| 7.9   	|
| Marietje 	| immunologie 	| 5     	|
| Marietje 	| BID         	| 9     	|

<div class="question">
##### Exercise `r les` {-}    {#onderzoektidyvraag}
The package tidyverse contains the built-in datasets:

* table1
* table2
* table3
* table4a
* table4b

Write code to inspect the data and argue if the tables are tidy
</div>

<details><summary>Click for the answer</summary>

To inspect for instance **table1**, just write `table1` in the console window.

There are three rules to make a dataset tidy:

* Each variable must have its own column.
* Each observation must have its own row.
* Each value must have its own cell.

**table1**: tidy

**table2**: non-tidy, violation of rule2. An observation is a country in a year, but each observation is spread across two rows.

**table3**: non-tidy, violation of rule3. The "rate" column contains both cases and population variables

**table4a/b**: non-tidy, violation of rule 1 and 2. The column names "1999" and "2000" represent values of the year variable, and each row represents two observations, not one.
</details>

## Making your data tidy: gathering

In [this exercise](#onderzoektidyvraag) we noted that table4a is not tidy: the column names '1999' and '2000' represent values of the year variable, and each row represents two observations, not one.

```{r , echo=FALSE, message=FALSE, out.width = "80%"}
knitr::include_graphics("images/03_7_nontidy_table4a.jpg")
```

To merge columns '1999' and '2000' into 1 column we can use the tidyverse function `pivot_longer()`:

```{r}
table4a_tidy <- pivot_longer(data = table4a, cols = c('1999', '2000'),  
                             names_to = "year",  values_to = "cases")
table4a_tidy
```

Alternatively we can use the pipe to redirect data to the `pivot_longer()` function:

###### Example
```{r}
table4a_tidy <- table4a %>% pivot_longer(cols = c('1999', '2000'),  
                                         names_to = "year",  values_to = "cases")
```


<div class="rstudio-tip">
Important: from now on we will often use the pipe %>% to redirect data into an R function: 
</div>

The %>% pipe symbol can be read as "followed by". The %>% symbol directs the **OUTPUT** of one R function as **INPUT** to the following R function.

dataset %>% function() %>% function() .. and so on

This way the steps of data manipulation are easier to follow for the reader. It is good practice to write clean / clear code that can be understand by other people. 




<div class="question">
##### Exercise `r les` {-} 
(a) Import datafile the first sheet gene_expression_c10.xlsx into R (it is already in the server folder data/lesson3)

(b) What are the dimension of the dataset?
</div>

<details><summary>Click for the answer</summary>
```{r}
#(a)
library(readxl)
gene_expression <- read_excel("data/lesson3/gene_expression_c10.xlsx")

#(b)
dim(gene_expression) # or look in the environment panel, upper right part of the screen
```
</details>

<div class="question">
##### Exercise `r les` {-} 
(a) Make the dataset of exercise_5.1 tidy

(b) What are now the dimension of the tidy dataset?
</div>

<details><summary>Click for the answer</summary>
```{r}
#(a)
gene_expression_tidy <- pivot_longer(data = gene_expression,
                                     cols = c('0h', '3h','12h', '24h', '48h'), 
                                     names_to = "time(hrs)", 
                                     values_to = "expression")
# or: 
gene_expression_tidy <- gene_expression %>% 
  pivot_longer(cols = c('0h', '3h','12h', '24h', '48h'), 
               names_to = "time(hrs)", values_to = "expression")

#(b)
dim(gene_expression_tidy)
```
</details>

## Making_your_data_tidy: spreading

In the [this exercise](#onderzoektidyvraag) we noted that table2 is not tidy: 2 row represents 1 observation.

```{r , echo=FALSE, message=FALSE, out.width = "60%"}
knitr::include_graphics("images/03_8_nontidy_table2.jpg")
```

Note that variable column "Type" contains the names of the variables "Cases" and "Population". This is the reason that two rows represent 1 observation. 

To merge the two rows, representing 1 observation, into 1 row we use the tidyverse function `pivot_wider()`. 

```{r}
table2_tidy <- pivot_wider(data = table2, names_from = "type", values_from = "count")
table2_tidy
```

Alternatively we can use the pipe to redirect the data to the pivot_wider() function:

###### Example
```{r}
table2_tidy <- table2 %>% pivot_wider(names_from = "type", values_from = "count")
```

<div class="question">
##### Exercise `r les` {-} 

(a) Import the second data sheet from datafile gene_expression_c10.xlsx (from the previous question, in server folder data/lesson3) into R

(b) Make the dataset tidy

</div>

<details><summary>Click for the answer</summary>
```{r}
#(a)
gene_expression_sheet2 <- read_excel("data/lesson3/gene_expression_c10.xlsx", sheet=2)

#(b)
gene_expression_sheet2_tidy <- pivot_wider(data = gene_expression_sheet2, 
                                           names_from = "assay", 
                                           values_from = "value")
# or: 
gene_expression_sheet2_tidy <- gene_expression_sheet2 %>% 
  pivot_wider(names_from = "assay", values_from ="value")
```
</details>


## Making_your_data_tidy: separate

In [this exercise](#onderzoektidyvraag) we noted that **table3** is not tidy: 2 values are present in 1 cell.

###### Example
```{r}
table3
```

To separate the values in two cells we use the tidyverse function `separate()`:

```{r}
table3_tidy <- separate(table3, rate, into = c("cases", "population"))
table3_tidy
```

The original variable "rate" contained "character" values, namely the two combined values separated by a forward slash. After the separation each new column ("cases" and "population") contain **numeric** values but the value types are still denoted as **characters**. To convert the character values into numeric values we use the **convert** option. 

###### Example
```{r}
table3_tidy <- separate(table3,  rate,  into = c("cases", "population"), convert = TRUE)
```

Normally you have to specify where the values need to be separated. In this case the forward slash character ("/"). The default option of the `separate()` funtion is to separate values based on any non-alphanumeric character (i.e. a character that isn’t a number or letter).  It is good practice though to write the separation character explicity in your code by using the sep="character" option. 

###### Example
```{r}
table3_tidy <- separate(table3, rate, into = c("cases", "population"), convert = TRUE,  sep = "/")
```

By using the **sep=** option we can also split values based on the a specific **number** of characters. For example we want to use the first three character of each country in our column instead of the full names. We can split the country names by the first three characters. 

###### Example
```{r}
# only 1 variable is defined: first 3 characters are stored in variable "country" replacing the original variable "country"
separate(table3_tidy, country, into = c("country"), sep = 3)
```


<div class="question">
##### Exercise `r les` {-} 

(a) Import datafile gene_expression_c10 (the one without the .xlsx) in the server folder data/lesson3 into R. The data colums are separated by a semicolon. 

(b) Make the dataset tidy

</div>

<details><summary>Click for the answer</summary>
```{r}
#(a)
gene_expression_1 <- read_csv2("data/lesson3/gene_expression_c10")

#(b)
gene_expression_1_tidy <- separate(gene_expression_1, "0h-3h-12h-24h-48h",
                             into = c("0h", "3h", "12h", "24h", "48h"),  sep = "!",  convert = TRUE)
# or: 
gene_expression_1_tidy <- gene_expression_1 %>% separate("0h-3h-12h-24h-48h",
                             into = c("0h", "3h", "12h", "24h", "48h"),  sep = "!",  convert = TRUE)
```

First we separate the values in 5 new variables. But the data is not tidy yet. We have to apply the function `pivot_longer()` because the new variables are not true variables but values of the variable "time_after_induction"
```{r}
gene_expression_1_tidy2 <- gene_expression_1_tidy %>%  pivot_longer(
  cols = c('0h', '3h', '12h', '24h', '48h'),
  names_to = "time_after_induction", values_to = "gene_expression")
```

</details>


## map functions
Generally, you will want to avoid repetitive code as it is prone to errors. So, if you want to apply the same function to a number of dataframes, you don't want to do this in a separate, very similar line for each one. 

For instance, let's say we want to perform a Shapiro-Wilk test on multiple conditions in a dataset. The smoking dataset used in this example is an unpaired experiment containing two different mice groups: control mice ("Controle") and a group of mice continuously exposed to cigarette smoke ("Rook"). The measurement values represent minutes of swimming until exhaustion. 


###### Example
```{r, message=F, error=F}
library(tidyverse)
smoking <- read_tsv("data/lesson3/smoking")
smoking #remember there are more rows, you only get shown the first few
```

To perform a Shapiro-Wilk test, you could simply type:
```{r, message=F, error=F}
shapiro.test(smoking$Controle)

shapiro.test(smoking$Rook)
```

If we want to perform the same function on all variables of a dataframe (tibble) we can make use of a series of map functions:

> `map()`       makes a list.

> `map_lgl()`   makes a logical vector

> `map_int()`   makes an integer vector

> `map_dbl()`   makes a numerical vector 

> `map_chr()`   makes a character vector

If we want to perform the Shapiro-Wilk test on each variable of dataset smoking we will use `map()` as the output of the `shapiro.test()` function is a list. For each variable of the smoking dataset, a list is produced and these lists are combined and stored in a new list (thus, the elements of the final list consist of lists!)

###### Example
```{r }
# shapiro.test() outputs multipe lines: use map() to store as list
SW_smoking <- smoking %>% map(shapiro.test)         
class(SW_smoking)                                                                                      

# the output of map() is a list containing two list elements
# each list element contains the p-value of the Shapiro-Wilk test
str(SW_smoking)
```

We see that the output of the Shapiro-Wilk test is stored as a list containing two elements, one for each variable. The elements in the list are lists themselves containing the summary information of the Shapiro-Wilk test.

What we are really interested in is the p-value (NOTE: in the list stored as p.value). We can automatically substract the p-values by adding another `map()` function. As the p-values are numbers we select the `map_dbl()` function so the p-values will be stored in a numeric vector.

###### Example
```{r }

smoking %>% map(shapiro.test) %>% map_dbl("p.value")
```

We see that both p-values are above 0.05. 

## Histogram

We will take a look at a hypothetical follow up experiment on the smoking data we used previously, using 200 mice who got nicotine patches or not. The dependent variable was minutes of swimming until exhaustion. I will spare the poor mice the exhaustion and generate the data for this example. Run this code to generate the fake data. rnorm() generates random numbers from a normal distribution, in this case 200 numbers, from a normal distribution with mean=180 or 160, and sd=15 or 25:
```{r}
set.seed(123)
smoking2 <- tibble(
  controle = rnorm(200,180,15),
  patch = rnorm(200,160,25)
)
```

Let's look at the minimum and maximum swimming times in the patch group:
```{r}
min(smoking2$patch) ## minimum minutes of swimming until exhaustion
max(smoking2$patch) ## maximum minutes of swimming until exhaustion
```

In order to see the distribution of the swimming times between the minimum and maximum values we will make a distribution plot, a histogram. It is build as:

 1. a layer with the data and aesthetics (aes)
 1. a layer telling ggplot we want a histogram
 1. a layer setting the title and axes

```{r}
ggplot(data = smoking2, aes(x = patch)) + 
  geom_histogram()+
  labs(
    title = "Distribution of swimming times of patch mice",
    x= "swimming time (min)",
    y= "count")
```

We can choose the bin size. The bin size, is the range on the x-axis that represents the width of each bar in the histogram. We can change it if we like:

```{r}
ggplot(data = smoking2, aes(x = patch)) + 
  geom_histogram(binwidth = 10)+
  labs(
    title = "Distribution of swimming times of control mice",
    x= "swimming time (min)",
    y= "count")
```

To make separate histograms for the control and the patch group in the same figure, we could make the data tidy and add an extra layer to ggplot called `facet_wrap()`:

```{r}
# tidy data: each variable in 1 column
smoking2_tidy <-  pivot_longer(data = smoking2, cols = c(controle, patch),  
                             names_to = "group",  values_to = "swimming_time")

# create histograms
ggplot(data = smoking2_tidy, aes(x = swimming_time)) + 
  geom_histogram(binwidth = 10)+
  labs(
    title = "Distribution of swimming times of control mice",
    x= "swimming time (min)",
    y= "count")+
  facet_wrap(~ group) 
```


